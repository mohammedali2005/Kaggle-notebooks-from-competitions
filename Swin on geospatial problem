{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":90650,"databundleVersionId":10557777,"sourceType":"competition"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet timm albumentations > /dev/null\n\nimport os\nimport cv2\nimport math\nimport timm\nimport random\nimport shutil\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nSEED = 42\n\ndef seed_everything(seed=SEED):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nseed_everything(SEED)\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T07:17:06.838317Z","iopub.execute_input":"2024-12-22T07:17:06.838737Z","iopub.status.idle":"2024-12-22T07:17:10.000373Z","shell.execute_reply.started":"2024-12-22T07:17:06.838702Z","shell.execute_reply":"2024-12-22T07:17:09.999255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CFG:\n    # Data paths\n    train_csv_path = \"/kaggle/input/datathon-ai-24/train.csv\"\n    test_csv_path  = \"/kaggle/input/datathon-ai-24/test.csv\"\n    train_img_dir  = \"/kaggle/input/datathon-ai-24/train\"\n    test_img_dir   = \"/kaggle/input/datathon-ai-24/test\"\n    csv_delimiter  = \";\"  # We use semicolon as per requirement\n    \n    # Model & Training\n    model_name     = \"swin_large_patch4_window12_384\"  # High-res variant of Swin Large\n    image_size     = 384  # Working resolution\n    batch_size     = 4    # Adjust for GPU memory constraints\n    num_workers    = 2\n    folds          = 2\n    epochs_stage1  = 3    # Freeze backbone\n    epochs_stage2  = 17   # Unfreeze\n    lr_backbone    = 2e-5\n    lr_head        = 5e-5\n    weight_decay   = 1e-5\n    \n    # Loss / Metric\n    use_haversine_loss = False  # Optionally True to train with Haversine\n    \n    # Gradient Accumulation\n    grad_accum_steps   = 1\n    \n    # Mixed Precision\n    apex_mixed_precision = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T07:18:04.906464Z","iopub.execute_input":"2024-12-22T07:18:04.906786Z","iopub.status.idle":"2024-12-22T07:18:04.911382Z","shell.execute_reply.started":"2024-12-22T07:18:04.906763Z","shell.execute_reply":"2024-12-22T07:18:04.910480Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\ndef haversine_distance(lat1, lon1, lat2, lon2):\n    \"\"\"\n    Compute haversine distance (km) between two points (lat1, lon1) and (lat2, lon2).\n    lat/lon in radians.\n    \"\"\"\n    R = 6371.0  # Earth radius in kilometers\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = torch.sin(dlat / 2)**2 + torch.cos(lat1) * torch.cos(lat2) * torch.sin(dlon / 2)**2\n    c = 2 * torch.arcsin(torch.sqrt(a))  # Use arcsin instead of atan2\n    return R * c\n\ndef haversine_rmse(preds, targets):\n    \"\"\"\n    preds, targets: (batch, 2) in degrees -> compute Haversine RMSE in km.\n    \"\"\"\n    lat1 = torch.deg2rad(preds[:, 0])  # Convert from degrees to radians\n    lon1 = torch.deg2rad(preds[:, 1])  # Convert from degrees to radians\n    lat2 = torch.deg2rad(targets[:, 0])  # Convert from degrees to radians\n    lon2 = torch.deg2rad(targets[:, 1])  # Convert from degrees to radians\n    \n    distances = haversine_distance(lat1, lon1, lat2, lon2)\n    return torch.sqrt((distances**2).mean())  # RMSE => sqrt of mean(dist^2)\n\n\ndef normalize_coords(df, lat_col=\"latitude\", lon_col=\"longitude\"):\n    \"\"\"\n    Shift & scale lat/long around the campus center.\n    Returns the updated df + normalization stats.\n    \"\"\"\n    lat_mean = df[lat_col].mean()\n    lon_mean = df[lon_col].mean()\n    \n    df[\"lat_norm\"] = df[lat_col] - lat_mean\n    df[\"lon_norm\"] = df[lon_col] - lon_mean\n    \n    lat_std = df[\"lat_norm\"].std()\n    lon_std = df[\"lon_norm\"].std()\n\n    df[\"lat_norm\"] /= lat_std\n    df[\"lon_norm\"] /= lon_std\n    \n    return df, (lat_mean, lon_mean, lat_std, lon_std)\n\ndef denormalize_coords(lat, lon, stats):\n    \"\"\"\n    Inverse of normalize_coords. stats = (lat_mean, lon_mean, lat_std, lon_std).\n    \"\"\"\n    lat_mean, lon_mean, lat_std, lon_std = stats\n    lat_out = lat * lat_std + lat_mean\n    lon_out = lon * lon_std + lon_mean\n    return lat_out, lon_out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T07:18:09.674290Z","iopub.execute_input":"2024-12-22T07:18:09.674714Z","iopub.status.idle":"2024-12-22T07:18:09.685344Z","shell.execute_reply.started":"2024-12-22T07:18:09.674681Z","shell.execute_reply":"2024-12-22T07:18:09.684497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Augmentations for training\ntrain_transform = A.Compose([\n    A.RandomResizedCrop(CFG.image_size, CFG.image_size, scale=(0.8, 1.0)),\n    A.HorizontalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.07, scale_limit=0.2, rotate_limit=30, p=0.5),\n    A.RGBShift(p=0.2),\n    A.RandomBrightnessContrast(p=0.2),\n    A.Normalize(),\n    ToTensorV2()\n])\n\n# Augmentations for validation\nvalid_transform = A.Compose([\n    A.Resize(CFG.image_size, CFG.image_size),\n    A.Normalize(),\n    ToTensorV2()\n])\n\n# TTA transform (flip)\ntta_transform = A.Compose([\n    A.Resize(CFG.image_size, CFG.image_size),\n    A.HorizontalFlip(p=1.0),\n    A.Normalize(),\n    ToTensorV2()\n])\n\nclass GeoDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, is_test=False, stats=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n        self.stats = stats  # (lat_mean, lon_mean, lat_std, lon_std) if needed\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        filename = row[\"filename\"]\n        img_path = os.path.join(self.img_dir, filename)\n        \n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            image = self.transform(image=image)[\"image\"]\n        \n        if self.is_test:\n            # No coordinates in test data\n            return image, filename\n        else:\n            # Return normalized lat/long\n            lat = torch.tensor(row[\"lat_norm\"], dtype=torch.float)\n            lon = torch.tensor(row[\"lon_norm\"], dtype=torch.float)\n            coords = torch.stack([lat, lon])  # shape (2,)\n            return image, coords","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T07:18:12.882390Z","iopub.execute_input":"2024-12-22T07:18:12.882715Z","iopub.status.idle":"2024-12-22T07:18:12.893169Z","shell.execute_reply.started":"2024-12-22T07:18:12.882687Z","shell.execute_reply":"2024-12-22T07:18:12.892420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SwinGeoModel(nn.Module):\n    def __init__(self, model_name=CFG.model_name, pretrained=True):\n        super().__init__()\n        # Create model using timm\n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        \n        # Remove default classifier head\n        in_features = self.backbone.head.in_features\n        self.backbone.reset_classifier(0)\n        \n        # Regression head (2 outputs -> lat, lon)\n        self.fc = nn.Sequential(\n            nn.Dropout(0.3),\n            nn.Linear(in_features, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, 2)\n        )\n        \n    def forward(self, x):\n        features = self.backbone(x)\n        out = self.fc(features)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T07:18:16.606821Z","iopub.execute_input":"2024-12-22T07:18:16.607099Z","iopub.status.idle":"2024-12-22T07:18:16.612396Z","shell.execute_reply.started":"2024-12-22T07:18:16.607077Z","shell.execute_reply":"2024-12-22T07:18:16.611515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def mse_loss(preds, targets):\n    return F.mse_loss(preds, targets)\n\ndef haversine_loss(preds, targets, stats):\n    \"\"\"\n    Convert normalized preds back to degrees, then compute haversine distance in km.\n    We'll treat it similarly to MSE by squaring distances.\n    \"\"\"\n    lat, lon = denormalize_coords(preds[:,0], preds[:,1], stats)\n    lat_t, lon_t = denormalize_coords(targets[:,0], targets[:,1], stats)\n    \n    latlon_pred = torch.stack([lat, lon], dim=1)\n    latlon_true = torch.stack([lat_t, lon_t], dim=1)\n    \n    dist = torch.pow(haversine_rmse(latlon_pred, latlon_true), 2)  # squared distance in km^2\n    return dist","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T07:18:18.660005Z","iopub.execute_input":"2024-12-22T07:18:18.660330Z","iopub.status.idle":"2024-12-22T07:18:18.665423Z","shell.execute_reply.started":"2024-12-22T07:18:18.660301Z","shell.execute_reply":"2024-12-22T07:18:18.664484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, epoch, stats, scaler=None):\n    model.train()\n    running_loss = 0.0\n    \n    for step, (images, coords) in enumerate(tqdm(dataloader, desc=f\"Train E{epoch}\")):\n        images = images.to(DEVICE)\n        coords = coords.to(DEVICE)\n        \n        with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n            outputs = model(images)\n            if CFG.use_haversine_loss:\n                loss = haversine_loss(outputs, coords, stats).mean()\n            else:\n                loss = mse_loss(outputs, coords)\n        \n        if scaler is not None:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n\n        # Gradient accumulation\n        if (step + 1) % CFG.grad_accum_steps == 0:\n            if scaler is not None:\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                optimizer.step()\n            optimizer.zero_grad()\n            \n            if scheduler is not None:\n                scheduler.step()\n\n        running_loss += loss.item() * images.size(0)\n        \n    epoch_loss = running_loss / len(dataloader.dataset)\n    return epoch_loss\n\ndef valid_one_epoch(model, dataloader, epoch, stats):\n    model.eval()\n    running_loss = 0.0\n    haversine_running = 0.0\n    \n    with torch.no_grad():\n        for images, coords in tqdm(dataloader, desc=f\"Valid E{epoch}\"):\n            images = images.to(DEVICE)\n            coords = coords.to(DEVICE)\n            \n            outputs = model(images)\n            \n            if CFG.use_haversine_loss:\n                loss = haversine_loss(outputs, coords, stats).mean()\n            else:\n                loss = mse_loss(outputs, coords)\n            \n            # Haversine RMSE metric\n            lat_pred, lon_pred = denormalize_coords(outputs[:,0], outputs[:,1], stats)\n            lat_true, lon_true = denormalize_coords(coords[:,0], coords[:,1], stats)\n            \n            latlon_pred = torch.stack([lat_pred, lon_pred], dim=1)\n            latlon_true = torch.stack([lat_true, lon_true], dim=1)\n            \n            haversine_dist = haversine_rmse(latlon_pred, latlon_true)\n            \n            running_loss += loss.item() * images.size(0)\n            haversine_running += haversine_dist.item() * images.size(0)\n    \n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_haversine = haversine_running / len(dataloader.dataset)\n    return epoch_loss, epoch_haversine","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T07:18:20.976263Z","iopub.execute_input":"2024-12-22T07:18:20.976616Z","iopub.status.idle":"2024-12-22T07:18:20.985749Z","shell.execute_reply.started":"2024-12-22T07:18:20.976568Z","shell.execute_reply":"2024-12-22T07:18:20.984871Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_training_folds():\n    \"\"\"\n    Run K-Fold training over CFG.folds splits, returning:\n      - paths to best checkpoints for each fold\n      - the (lat_mean, lon_mean, lat_std, lon_std) stats used for normalization\n    \"\"\"\n    # Read training CSV with semicolon delimiter\n    df = pd.read_csv(CFG.train_csv_path, delimiter=CFG.csv_delimiter)\n    \n    # Normalize coords\n    df, stats = normalize_coords(df, lat_col=\"latitude\", lon_col=\"longitude\")\n    \n    # Create K-Fold column\n    kf = KFold(n_splits=CFG.folds, shuffle=True, random_state=SEED)\n    df[\"fold\"] = -1\n    for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n        df.loc[val_idx, \"fold\"] = fold\n    \n    # Prepare arrays for out-of-fold predictions\n    oof_predictions = np.zeros((len(df), 2), dtype=np.float32)\n    models_paths = []\n    \n    for fold in range(CFG.folds):\n        print(f\"========== Fold: {fold} training ==========\")\n        \n        train_df = df[df.fold != fold].reset_index(drop=True)\n        valid_df = df[df.fold == fold].reset_index(drop=True)\n        \n        train_dataset = GeoDataset(\n            train_df,\n            CFG.train_img_dir,\n            transform=train_transform,\n            is_test=False,\n            stats=stats\n        )\n        valid_dataset = GeoDataset(\n            valid_df,\n            CFG.train_img_dir,\n            transform=valid_transform,\n            is_test=False,\n            stats=stats\n        )\n        \n        train_loader = DataLoader(\n            train_dataset,\n            batch_size=CFG.batch_size,\n            shuffle=True,\n            num_workers=CFG.num_workers,\n            pin_memory=True,\n            drop_last=True\n        )\n        valid_loader = DataLoader(\n            valid_dataset,\n            batch_size=CFG.batch_size,\n            shuffle=False,\n            num_workers=CFG.num_workers,\n            pin_memory=True,\n            drop_last=False\n        )\n        \n        # Initialize model\n        model = SwinGeoModel(model_name=CFG.model_name, pretrained=True).to(DEVICE)\n        \n        # Separate backbone & head params for differential LR\n        backbone_params = []\n        head_params = []\n        for name, param in model.named_parameters():\n            if \"backbone\" in name:\n                backbone_params.append(param)\n            else:\n                head_params.append(param)\n        \n        # Stage 1: freeze backbone\n        for param in backbone_params:\n            param.requires_grad = False\n        \n        optimizer = optim.AdamW([\n            {\"params\": backbone_params, \"lr\": CFG.lr_backbone},\n            {\"params\": head_params, \"lr\": CFG.lr_head},\n        ], weight_decay=CFG.weight_decay)\n\n        # LR schedule: warmup + cosine\n        total_steps = (len(train_loader) // CFG.grad_accum_steps) * (CFG.epochs_stage1 + CFG.epochs_stage2)\n        warmup_steps = int(0.1 * total_steps)\n        \n        def lr_lambda(current_step):\n            if current_step < warmup_steps:\n                return float(current_step) / float(warmup_steps)\n            progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n            return 0.5 * (1.0 + math.cos(math.pi * progress))\n        \n        scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n        \n        scaler = torch.cuda.amp.GradScaler() if CFG.apex_mixed_precision and DEVICE.type == 'cuda' else None\n        \n        # Train - Stage 1\n        best_score = float(\"inf\")\n        for epoch in range(1, CFG.epochs_stage1 + 1):\n            train_loss = train_one_epoch(model, optimizer, scheduler, train_loader, epoch, stats, scaler=scaler)\n            valid_loss, valid_haversine = valid_one_epoch(model, valid_loader, epoch, stats)\n            \n            print(f\"[E{epoch}/Stage1] train_loss={train_loss:.4f} | valid_loss={valid_loss:.4f} | haversine={valid_haversine:.4f} km\")\n            \n            if valid_haversine < best_score:\n                best_score = valid_haversine\n                torch.save(model.state_dict(), f\"best_fold{fold}.pth\")\n        \n        # Unfreeze all - Stage 2\n        for param in backbone_params:\n            param.requires_grad = True\n        \n        # Load best from stage1\n        model.load_state_dict(torch.load(f\"best_fold{fold}.pth\"))\n        \n        for epoch in range(CFG.epochs_stage1 + 1, CFG.epochs_stage1 + CFG.epochs_stage2 + 1):\n            train_loss = train_one_epoch(model, optimizer, scheduler, train_loader, epoch, stats, scaler=scaler)\n            valid_loss, valid_haversine = valid_one_epoch(model, valid_loader, epoch, stats)\n            \n            print(f\"[E{epoch}/Stage2] train_loss={train_loss:.4f} | valid_loss={valid_loss:.4f} | haversine={valid_haversine:.4f} km\")\n            \n            if valid_haversine < best_score:\n                best_score = valid_haversine\n                torch.save(model.state_dict(), f\"best_fold{fold}.pth\")\n        \n        print(f\"Fold {fold} - Best Haversine: {best_score:.4f} km\")\n        models_paths.append(f\"best_fold{fold}.pth\")\n        \n        # OOF Predictions\n        model.load_state_dict(torch.load(f\"best_fold{fold}.pth\"))\n        model.eval()\n        preds = []\n        with torch.no_grad():\n            for imgs, coords in DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False):\n                imgs = imgs.to(DEVICE)\n                outs = model(imgs).cpu()\n                preds.append(outs)\n                \n        preds = torch.cat(preds, dim=0).numpy()\n        oof_predictions[df[df.fold == fold].index, :] = preds\n    \n    # Compute OOF Haversine\n    lat_oof, lon_oof = denormalize_coords(oof_predictions[:,0], oof_predictions[:,1], stats)\n    lat_gt, lon_gt   = denormalize_coords(df[\"lat_norm\"].values, df[\"lon_norm\"].values, stats)\n    \n    preds_tensor = torch.from_numpy(np.stack([lat_oof, lon_oof], axis=1))\n    gts_tensor   = torch.from_numpy(np.stack([lat_gt, lon_gt], axis=1))\n    \n    final_haversine = haversine_rmse(preds_tensor, gts_tensor).item()\n    print(f\"OOF Haversine RMSE = {final_haversine:.4f} km\")\n    \n    return models_paths, stats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T07:18:23.968297Z","iopub.execute_input":"2024-12-22T07:18:23.968585Z","iopub.status.idle":"2024-12-22T07:18:23.982945Z","shell.execute_reply.started":"2024-12-22T07:18:23.968565Z","shell.execute_reply":"2024-12-22T07:18:23.982139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_test(models_paths, stats):\n    \"\"\"\n    Use an ensemble of the best fold models to predict lat/long on the test set,\n    then save submission.csv.\n    \"\"\"\n    # Read test CSV with semicolon delimiter\n    test_df = pd.read_csv(CFG.test_csv_path, delimiter=CFG.csv_delimiter)\n    \n    test_dataset = GeoDataset(\n        test_df,\n        CFG.test_img_dir,\n        transform=valid_transform,\n        is_test=True,\n        stats=stats\n    )\n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=CFG.batch_size,\n        shuffle=False,\n        num_workers=CFG.num_workers\n    )\n    \n    predictions = np.zeros((len(test_df), 2), dtype=np.float32)\n    \n    def inference_tta(model, img_batch):\n        # Normal inference\n        with torch.no_grad():\n            out1 = model(img_batch.to(DEVICE))\n        \n        # Flipped inference\n        flipped = []\n        for im in img_batch:\n            data = tta_transform(image=im.permute(1,2,0).cpu().numpy())\n            flipped.append(data[\"image\"])\n        flipped = torch.stack(flipped).to(DEVICE)\n        with torch.no_grad():\n            out2 = model(flipped)\n        \n        return (out1 + out2) / 2.0\n    \n    for fold, ckpt_path in enumerate(models_paths):\n        print(f\"Inference with fold {fold}: {ckpt_path}\")\n        model = SwinGeoModel(model_name=CFG.model_name, pretrained=False).to(DEVICE)\n        model.load_state_dict(torch.load(ckpt_path))\n        model.eval()\n        \n        preds_fold = []\n        for imgs, filenames in tqdm(test_loader, desc=f\"Predict fold {fold}\"):\n            outs = inference_tta(model, imgs)\n            preds_fold.append(outs.cpu())\n            \n        preds_fold = torch.cat(preds_fold, dim=0).numpy()\n        predictions += preds_fold\n    \n    # Average across folds\n    predictions /= len(models_paths)\n    \n    # Denormalize\n    lat_pred, lon_pred = denormalize_coords(predictions[:,0], predictions[:,1], stats)\n    \n    test_df[\"latitude\"] = lat_pred\n    test_df[\"longitude\"] = lon_pred\n    \n    # Save final predictions\n    test_df.to_csv(\"submission.csv\", index=False, float_format=\"%.15f\")\n    print(\"submission.csv saved with predicted lat/long.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T08:53:09.280305Z","iopub.execute_input":"2024-12-22T08:53:09.280655Z","iopub.status.idle":"2024-12-22T08:53:09.289036Z","shell.execute_reply.started":"2024-12-22T08:53:09.280621Z","shell.execute_reply":"2024-12-22T08:53:09.288212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) Train with K-Fold\nmodels_paths, stats = run_training_folds()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T07:18:31.689493Z","iopub.execute_input":"2024-12-22T07:18:31.689837Z","iopub.status.idle":"2024-12-22T08:53:03.238192Z","shell.execute_reply.started":"2024-12-22T07:18:31.689812Z","shell.execute_reply":"2024-12-22T08:53:03.236741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2) Predict on test set\n# Read training CSV with semicolon delimiter\ndf = pd.read_csv(CFG.train_csv_path, delimiter=CFG.csv_delimiter)\n\nmodels_paths = ['/kaggle/working/best_fold0.pth']\n# Normalize coords\ndf, stats = normalize_coords(df, lat_col=\"latitude\", lon_col=\"longitude\")\npredict_test(models_paths, stats)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T08:53:33.185413Z","iopub.execute_input":"2024-12-22T08:53:33.185740Z","iopub.status.idle":"2024-12-22T08:54:52.898885Z","shell.execute_reply.started":"2024-12-22T08:53:33.185713Z","shell.execute_reply":"2024-12-22T08:54:52.897911Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}